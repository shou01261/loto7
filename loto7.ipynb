{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shou01261/loto7/blob/main/loto7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e-G0pOf7qFNU",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "77e9510a-78f9-4b7a-e69f-d0699a50a54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-73cea70b3692>:218: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler(enabled=True)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s]<ipython-input-1-73cea70b3692>:248: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(dtype=torch.bfloat16):\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 10/10 [00:02<00:00,  4.86it/s]\n",
            "<ipython-input-1-73cea70b3692>:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.inference_mode(), torch.cuda.amp.autocast(): # 推論モードと自動混合精度を使用\n",
            "Epoch 1: 100%|██████████| 10/10 [00:02<00:00,  4.46it/s]\n",
            "Epoch 1:  10%|█         | 1/10 [00:00<00:04,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-73cea70b3692>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-73cea70b3692>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;31m# Pass the dataset to train_epoch for prediction feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# モデル保存 (既存のロジック、epoch % save_interval == 0 で保存)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-73cea70b3692>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch, loader, dataset)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# 勾配スケーリングを使用してバックワードパスを実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# 勾配累積が設定されている場合、指定されたステップごとにオプティマイザーステップを実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import math\n",
        "import logging\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import pandas as pd\n",
        "import requests\n",
        "from collections import Counter\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "# パフォーマンス設定\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "def generate_ensemble_predictions(models, dataset, draw_number, num_preds=5, visualize=True, use_predicted=False):\n",
        "    \"\"\"\n",
        "    複数のモデルを使用してアンサンブル予測を生成する関数\n",
        "\n",
        "    Args:\n",
        "        models (list): EnhancedLoto7Transformer モデルのリスト\n",
        "        dataset (EnhancedLoto7Dataset): 使用するデータセット\n",
        "        draw_number (int): 予測したい開催回\n",
        "        num_preds (int): 各モデルから生成する予測の数\n",
        "        visualize (bool): 予測結果を可視化するかどうか\n",
        "        use_predicted (bool): 未来の開催回の場合に過去の予測結果を使用するかどうか\n",
        "\n",
        "    Returns:\n",
        "        list: アンサンブル予測の結果リスト (例: [当選数字7個のリスト, ...])\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    all_predictions = []\n",
        "\n",
        "    # 予測対象の開催回に対応する入力データを取得\n",
        "    try:\n",
        "        recent_src = dataset.get_recent_data_for_prediction(draw_number, use_predicted=use_predicted).unsqueeze(0).to(device)\n",
        "    except ValueError as e:\n",
        "        logger.error(f\"Error getting data for prediction for draw {draw_number}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "    # 各モデルで予測を実行\n",
        "    for i, model in enumerate(models):\n",
        "        model.eval() # 推論モード\n",
        "        with torch.inference_mode(), torch.cuda.amp.autocast():\n",
        "            logits = model(recent_src) # outputs: (batch, 7, 37)\n",
        "            probs = F.softmax(logits, dim=-1) # (batch, 7, 37)\n",
        "\n",
        "            # num_preds 個の予測を生成 (サンプリング)\n",
        "            for _ in range(num_preds):\n",
        "                sampled_numbers = []\n",
        "                for pos in range(7):\n",
        "                    # 確率分布から数字をサンプリング (重複あり)\n",
        "                    sampled_idx = torch.multinomial(probs[0, pos], 1).item()\n",
        "                    sampled_numbers.append(sampled_idx + 1) # 0-36を1-37に戻す\n",
        "                all_predictions.append(sampled_numbers)\n",
        "\n",
        "    # アンサンブル予測の統合 (例: 最も頻繁に出現する数字を選択)\n",
        "    # 各位置 (1st, 2nd, ...) ごとに最も出現頻度の高い数字を選択\n",
        "    ensemble_result = []\n",
        "    for pos in range(7):\n",
        "        pos_predictions = [pred[pos] for pred in all_predictions]\n",
        "        # 最頻値を計算。同じ頻度の場合は数値の小さい方を選択（または別のルール）\n",
        "        count = Counter(pos_predictions)\n",
        "        most_common = count.most_common()\n",
        "        if most_common:\n",
        "            # 頻度が最大の候補をすべて取得\n",
        "            max_freq = most_common[0][1]\n",
        "            candidates = sorted([num for num, freq in most_common if freq == max_freq])\n",
        "            ensemble_result.append(candidates[0]) # 最小の候補を選択\n",
        "        else:\n",
        "            # 予測がない場合はランダムな数字を選択 (例として)\n",
        "            ensemble_result.append(np.random.randint(1, 38))\n",
        "\n",
        "    logger.info(f\"Ensemble prediction for draw {draw_number}: {ensemble_result}\")\n",
        "\n",
        "    # 可視化\n",
        "    if visualize:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        all_numbers = [num for pred in all_predictions for num in pred]\n",
        "        plt.hist(all_numbers, bins=range(1, 39), align='left', rwidth=0.8)\n",
        "        plt.xticks(range(1, 38))\n",
        "        plt.xlabel(\"Loto 7 Numbers\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.title(f\"Number Distribution from Ensemble Predictions for Draw {draw_number}\")\n",
        "        plt.grid(axis='y', alpha=0.75)\n",
        "        plt.show()\n",
        "\n",
        "    return [ensemble_result] # 統合された予測結果をリストで返す\n",
        "# ========================================\n",
        "# データセット定義（未来予測機能追加版）\n",
        "# ========================================\n",
        "class EnhancedLoto7Dataset(Dataset):\n",
        "    def __init__(self, csv_url, window_size=10, predict_future=False):\n",
        "        self.window_size = window_size\n",
        "        self.predict_future = predict_future\n",
        "        self.prediction_history = deque(maxlen=window_size) if predict_future else None\n",
        "\n",
        "        # データ取得と前処理\n",
        "        response = requests.get(csv_url)\n",
        "        response.encoding = 'shift_jis'\n",
        "        df = pd.read_csv(io.StringIO(response.text))\n",
        "\n",
        "        # 数字を整数として取得（1～37を0～36に変換）\n",
        "        raw_draws = df[['第1数字','第2数字','第3数字','第4数字','第5数字','第6数字','第7数字']].values.astype(np.int64)\n",
        "        self.draws_int = raw_draws - 1  # ターゲット（0～36）\n",
        "        # 入力用は正規化（0～1）\n",
        "        self.draws_norm = (raw_draws - 1) / 36.0\n",
        "\n",
        "        # 開催回の正規化：各回の開催回を1次元の数値として扱う\n",
        "        self.draw_numbers = df['開催回'].values\n",
        "        self.min_draw_number = self.draw_numbers.min()\n",
        "        self.max_draw_number = self.draw_numbers.max()\n",
        "        self.draw_numbers_norm = (self.draw_numbers - self.min_draw_number) / (self.max_draw_number - self.min_draw_number)\n",
        "\n",
        "        # サンプル生成：各サンプルは過去window_size回分のデータ\n",
        "        # 各回の入力は、開催回（1次元）と宝くじ数字（7次元）の合計8次元\n",
        "        self.samples = []\n",
        "        for i in range(self.window_size, len(self.draws_int)):\n",
        "            src = np.concatenate([\n",
        "                self.draw_numbers_norm[i-self.window_size:i].reshape(-1, 1),  # shape: (window_size, 1)\n",
        "                self.draws_norm[i-self.window_size:i]                    # shape: (window_size, 7)\n",
        "            ], axis=1).flatten()  # フラットなベクトル（長さ = window_size * 8）\n",
        "            tgt = self.draws_int[i]  # 当該回の7数字（整数 0～36 の配列）\n",
        "            self.samples.append((torch.FloatTensor(src), torch.LongTensor(tgt)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "    def add_prediction(self, draw_number, prediction):\n",
        "        \"\"\"未来予測用に予測結果を追加\"\"\"\n",
        "        if not self.predict_future:\n",
        "            return\n",
        "\n",
        "        # 予測結果を正規化して保存 (predictionは1～37の数字)\n",
        "        norm_pred = (np.array(prediction) - 1) / 36.0\n",
        "        norm_draw = (draw_number - self.min_draw_number) / (self.max_draw_number - self.min_draw_number)\n",
        "\n",
        "        self.prediction_history.append((norm_draw, norm_pred))\n",
        "\n",
        "    def get_recent_data_for_prediction(self, draw_number, use_predicted=False):\n",
        "        \"\"\"\n",
        "      指定された開催回に基づいて、過去のデータをウィンドウサイズ分取得する\n",
        "      use_predicted=Trueの場合、過去の予測結果も使用する\n",
        "      \"\"\"\n",
        "        # 開催回のインデックスを取得\n",
        "        if draw_number not in self.draw_numbers:\n",
        "            # 未来の開催回の場合、最後の開催回から増分を計算\n",
        "            last_draw = self.draw_numbers[-1]\n",
        "            if draw_number <= last_draw:\n",
        "                raise ValueError(f\"指定された開催回 {draw_number} はデータセット内に存在しません。\")\n",
        "\n",
        "            # 未来の開催回の場合、予測履歴を使用\n",
        "            if not use_predicted or len(self.prediction_history) < self.window_size:\n",
        "                # 予測履歴が不足している場合は実際のデータを使用\n",
        "                idx = len(self.draw_numbers) - 1\n",
        "            else:\n",
        "                # 予測履歴からデータを構築\n",
        "                pred_data = list(self.prediction_history)[-self.window_size:]\n",
        "                src = np.concatenate([\n",
        "                    np.array([d[0] for d in pred_data]).reshape(-1, 1),\n",
        "                    np.array([d[1] for d in pred_data])\n",
        "                ], axis=1).flatten()\n",
        "                return torch.FloatTensor(src)\n",
        "        else:\n",
        "            idx = np.where(self.draw_numbers == draw_number)[0][0]\n",
        "\n",
        "        # ウィンドウサイズ分の過去データが存在するか確認\n",
        "        if idx < self.window_size:\n",
        "            raise ValueError(f\"指定された開催回 {draw_number} のインデックス {idx} はウィンドウサイズ {self.window_size} よりも小さいため、過去データが不足しています。\")\n",
        "\n",
        "        # 過去のデータをウィンドウサイズ分取得\n",
        "        src = np.concatenate([\n",
        "            self.draw_numbers_norm[idx-self.window_size:idx].reshape(-1, 1),  # shape: (window_size, 1)\n",
        "            self.draws_norm[idx-self.window_size:idx]                    # shape: (window_size, 7)\n",
        "        ], axis=1).flatten()  # フラットなベクトル（長さ = window_size * 8）\n",
        "        return torch.FloatTensor(src)\n",
        "\n",
        "# ========================================\n",
        "# トレーナー定義（複数開催回予測機能追加版）\n",
        "# ========================================\n",
        "class AdvancedTrainer:\n",
        "    def __init__(self, model, batch_size=256, grad_accum=2, predict_draw_numbers=None, model_idx=0):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = model.to(self.device)\n",
        "        self.predict_draw_numbers = predict_draw_numbers if predict_draw_numbers else []\n",
        "        self.model_idx = model_idx # モデルのインデックスを追加\n",
        "\n",
        "        # 標準のAdamWオプティマイザを使用\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=2e-7,\n",
        "            betas=(0.9, 0.98),\n",
        "            weight_decay=1e-4\n",
        "        )\n",
        "\n",
        "        # 学習率スケジューラ\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=1.0001)\n",
        "        self.min_lr = float('inf') # 追跡する最小学習率を初期化\n",
        "        self.min_lr_epoch = -1 # 最小学習率を記録したエポック\n",
        "        self.saved_best_lr_model = False # 最小LRでのモデルを一度だけ保存するためのフラグ\n",
        "        # 省メモリ設定\n",
        "        self.scaler = GradScaler(enabled=True)\n",
        "        # 分類タスクのため CrossEntropyLoss を利用\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.batch_size = batch_size\n",
        "        self.grad_accum = grad_accum\n",
        "        self.hist_loss = []\n",
        "        self.hist_lr = []\n",
        "        # 予測履歴はエポックごとのリストを格納\n",
        "        # ファイル保存に切り替えるため、メモリ上には保持しないか、バッファリングのみ行う\n",
        "        # self.hist_predictions = {draw_num: [] for draw_num in self.predict_draw_numbers}\n",
        "    def train_epoch(self, epoch, loader, dataset=None):\n",
        "        \"\"\"\n",
        "        単一のエポックのトレーニングを実行し、オプションで指定された開催回に対して予測を行う\n",
        "\n",
        "        Args:\n",
        "            epoch (int): 現在のエポック数\n",
        "            loader (DataLoader): トレーニングデータのデータローダー\n",
        "            dataset (EnhancedLoto7Dataset, optional): 予測に使用するデータセット。予測機能を使用しない場合はNone.\n",
        "        \"\"\"\n",
        "        self.model.train() # モデルをトレーニングモードに設定\n",
        "        total_loss = 0 # エポック全体の合計ロスを初期化\n",
        "        self.optimizer.zero_grad() # 勾配をリセット\n",
        "\n",
        "        # データローダーからバッチを取得し、トレーニングループを実行\n",
        "        for i, (src, tgt) in enumerate(tqdm(loader, desc=f\"Epoch {epoch}\")):\n",
        "            # データを適切なデバイス (CPU/GPU) に移動\n",
        "            src = src.to(self.device, non_blocking=True)\n",
        "            tgt = tgt.to(self.device, non_blocking=True)  # ターゲットの形状: (batch, 7)\n",
        "\n",
        "            # 自動混合精度 (Autocast) を使用してフォワードパスを実行\n",
        "            with autocast(dtype=torch.bfloat16):\n",
        "                outputs = self.model(src)  # モデルの出力: (batch, 7, 37)\n",
        "                # CrossEntropyLoss の入力形状に合わせるために reshape\n",
        "                # 出力を (batch*7, 37), ターゲットを (batch*7,) に変換\n",
        "                loss = self.loss_fn(outputs.view(-1, outputs.shape[-1]), tgt.view(-1)) / self.grad_accum\n",
        "\n",
        "            # 勾配スケーリングを使用してバックワードパスを実行\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            # 勾配累積が設定されている場合、指定されたステップごとにオプティマイザーステップを実行\n",
        "            if (i+1) % self.grad_accum == 0:\n",
        "                self.scaler.step(self.optimizer) # スケーリングされた勾配でオプティマイザーステップ\n",
        "                self.scaler.update() # 勾配スケーラーを更新\n",
        "                self.optimizer.zero_grad() # 勾配をゼロにリセット\n",
        "                # ここでのスケジューラーステップはバッチごとではなく、エポックの最後に変更することも検討\n",
        "                # self.scheduler.step(epoch + i / len(loader)) # バッチごとのスケジューラーステップの例 (現在コメントアウト)\n",
        "\n",
        "            # バッチのロスを合計ロスに加算 (勾配累積による正規化前のロスを加えることで平均を正しく計算)\n",
        "            total_loss += loss.item() * self.grad_accum # grad_accum で割った分を元に戻す\n",
        "\n",
        "        # エポックの平均ロスを計算\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        # 現在の学習率を取得\n",
        "        current_lr = self.scheduler.get_last_lr()[0] # エポック終了時点のLRを取得\n",
        "        # ロスと学習率の履歴を記録\n",
        "        self.hist_loss.append(avg_loss)\n",
        "        self.hist_lr.append(current_lr) # LRをリストに追加\n",
        "        # ロギング\n",
        "        logger.info(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | LR: {current_lr:.9e}\")\n",
        "\n",
        "        # エポック終了後に学習率スケジューラーステップを適用\n",
        "        # DataLoader のイテレーションが完了した後に一度だけステップを実行\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # --- 未来予測機能 ---\n",
        "        # 指定された開催回に対して予測を行い、結果をファイルに追記\n",
        "# Inside AdvancedTrainer.train_epoch method, in the prediction block\n",
        "        if self.predict_draw_numbers and dataset:\n",
        "            self.model.eval()\n",
        "            with torch.inference_mode(), torch.cuda.amp.autocast():\n",
        "                num_preds_per_model = 5\n",
        "                logger.info(f\"Predicting for draw numbers: {self.predict_draw_numbers} at epoch {epoch} for model {self.model_idx}\") # 予測対象の開催回をログ出力\n",
        "                logger.info(f\"Current working directory during prediction: {os.getcwd()}\") # カレントディレクトリをログ出力\n",
        "\n",
        "                for draw_num in self.predict_draw_numbers:\n",
        "                    try:\n",
        "                        use_predicted = draw_num > dataset.draw_numbers[-1]\n",
        "                        logger.info(f\"Attempting prediction for draw {draw_num} (use_predicted: {use_predicted})\")\n",
        "\n",
        "                        try:\n",
        "                            recent_src = dataset.get_recent_data_for_prediction(draw_num, use_predicted=use_predicted).unsqueeze(0).to(self.device)\n",
        "                            logits = self.model(recent_src)\n",
        "                            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "                            single_model_predictions_for_draw = []\n",
        "                            for _ in range(num_preds_per_model):\n",
        "                                sampled_numbers = []\n",
        "                                for pos in range(7):\n",
        "                                    sampled_idx = torch.multinomial(probs[0, pos], 1).item()\n",
        "                                    sampled_numbers.append(sampled_idx + 1)\n",
        "                                single_model_predictions_for_draw.append(sampled_numbers)\n",
        "\n",
        "                            logger.info(f\"Generated {len(single_model_predictions_for_draw)} predictions for draw {draw_num} at epoch {epoch} by model {self.model_idx}.\")\n",
        "                            if single_model_predictions_for_draw:\n",
        "                                logger.info(f\"Example prediction: {single_model_predictions_for_draw[0]}\") # 生成された予測の例をログ出力\n",
        "                            else:\n",
        "                                logger.warning(f\"No predictions generated for draw {draw_num} at epoch {epoch}.\")\n",
        "\n",
        "\n",
        "                        except ValueError as e:\n",
        "                            logger.warning(f\"Could not get data for prediction for draw {draw_num} at epoch {epoch}: {str(e)}. Skipping prediction for this draw.\")\n",
        "                            continue # この開催回に対するこれ以上の処理をスキップ\n",
        "                        except Exception as data_e:\n",
        "                            logger.error(f\"An unexpected error occurred getting data for draw {draw_num}: {data_e}\")\n",
        "                            continue\n",
        "\n",
        "\n",
        "                        # 予測結果をファイルに追記\n",
        "                        history_file = f\"model{self.model_idx}_{draw_num}_predictions.csv\"\n",
        "                        logger.info(f\"Attempting to save predictions to: {history_file}\")\n",
        "\n",
        "                        # ファイルが存在しない場合はヘッダーが必要\n",
        "                        header_needed = not os.path.exists(history_file)\n",
        "                        logger.info(f\"Header needed for {history_file}: {header_needed}\")\n",
        "\n",
        "\n",
        "                        # 生成された予測データがある場合のみ保存\n",
        "                        if single_model_predictions_for_draw:\n",
        "                            all_preds_str = \"_\".join([\" \".join(map(str, pred)) for pred in single_model_predictions_for_draw])\n",
        "\n",
        "                            header_row = ['Epoch', 'Loss', 'LR', 'All_Predictions']\n",
        "                            row_to_save = [epoch, avg_loss, current_lr, all_preds_str]\n",
        "\n",
        "                            df_history = pd.DataFrame([row_to_save], columns=header_row)\n",
        "\n",
        "                            try:\n",
        "                                # ファイルに保存 (存在しない場合はヘッダー付きで新規作成、存在する場合はヘッダーなしで追記)\n",
        "                                if header_needed:\n",
        "                                    df_history.to_csv(history_file, mode='w', header=True, index=False)\n",
        "                                    logger.info(f\"Saved predictions to {history_file} with header (mode='w').\")\n",
        "                                else:\n",
        "                                    df_history.to_csv(history_file, mode='a', header=False, index=False)\n",
        "                                    logger.info(f\"Appended predictions to {history_file} (mode='a').\")\n",
        "                            except Exception as save_e:\n",
        "                                logger.error(f\"Error saving predictions to {history_file}: {save_e}\")\n",
        "\n",
        "                        else:\n",
        "                            logger.warning(f\"No predictions to save for draw {draw_num} at epoch {epoch} by model {self.model_idx} after generation check.\")\n",
        "\n",
        "                        # 未来の開催回に対する予測であり、かつ予測が生成された場合、データセットの履歴に最初の予測結果を追加\n",
        "                        if use_predicted and single_model_predictions_for_draw:\n",
        "                            try:\n",
        "                                dataset.add_prediction(draw_num, single_model_predictions_for_draw[0])\n",
        "                                logger.info(f\"Added prediction for draw {draw_num} to dataset history for use_predicted.\")\n",
        "                            except Exception as add_e:\n",
        "                                logger.error(f\"Error adding prediction to dataset history for draw {draw_num}: {add_e}\")\n",
        "\n",
        "                    except Exception as overall_e:\n",
        "                        # 予測または保存中に発生したその他のエラーを捕捉\n",
        "                        logger.error(f\"An overall error occurred during prediction or saving for draw {draw_num} at epoch {epoch}: {overall_e}\")\n",
        "# ========================================\n",
        "# Loto7 Transformer モデル定義\n",
        "# ========================================\n",
        "class EnhancedLoto7Transformer(nn.Module):\n",
        "    def __init__(self, window_size=10, d_model=128, nhead=8, num_layers=6, num_classes=37):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.input_dim = 8  # 各時刻の入力は開催回1次元 + 宝くじ数字7次元\n",
        "\n",
        "        # 開催回と宝くじ数字をそれぞれ別個に埋め込む\n",
        "        self.draw_num_embed = nn.Linear(1, d_model // 4)\n",
        "        self.lottery_embed = nn.Linear(7, d_model - d_model // 4)\n",
        "        self.combined_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.rotary = EnhancedRotaryEmbedding(d_model)\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EnhancedTransformerEncoder(d_model, nhead) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_model, num_classes)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "         for p in self.parameters():\n",
        "             if p.dim() > 1:\n",
        "                 nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src):\n",
        "         # src はフラットなベクトル（サイズ = window_size * input_dim）\n",
        "         # (batch, window_size, input_dim) に変形\n",
        "         src = src.view(-1, self.window_size, self.input_dim)\n",
        "         # 開催回（1次元）と宝くじ数字（7次元）を分離\n",
        "         draw_num = src[:, :, :1]       # shape: (batch, window_size, 1)\n",
        "         lottery_nums = src[:, :, 1:]     # shape: (batch, window_size, 7)\n",
        "         draw_emb = self.draw_num_embed(draw_num)      # (batch, window_size, d_model/4)\n",
        "         lottery_emb = self.lottery_embed(lottery_nums)  # (batch, window_size, d_model - d_model/4)\n",
        "         combined = torch.cat([draw_emb, lottery_emb], dim=-1)  # (batch, window_size, d_model)\n",
        "         combined = self.combined_proj(combined)\n",
        "\n",
        "         # ロータリエンベディングの適用\n",
        "         pos = self.rotary(combined)\n",
        "         combined = apply_rotary_pos_emb(pos, combined)\n",
        "         combined = self.dropout(combined)\n",
        "\n",
        "         for layer in self.encoder_layers:\n",
        "              combined = layer(combined)\n",
        "\n",
        "         # 最後の7タイムステップから各数字の予測を生成（出力 shape: (batch, 7, 37)）\n",
        "         return self.fc_out(combined[:, -7:])\n",
        "\n",
        "# ========================================\n",
        "# メイン処理（未来予測対応版）\n",
        "# ========================================\n",
        "def main():\n",
        "    # コマンドライン引数の解析\n",
        "    mode = 'train'  # デフォルトはトレーニングモード\n",
        "    predict_only = False\n",
        "    predict_draw_numbers = []\n",
        "\n",
        "    if len(sys.argv) > 1:\n",
        "        if mode == 'predict':\n",
        "            predict_only = True\n",
        "            # 予測のみモードの場合、予測したい開催回を直接指定するか、入力から取得\n",
        "            # ここでは仮に固定値を設定するか、必要に応じてユーザー入力を求めます\n",
        "            predict_draw_numbers = [620, 621, 622] # 例\n",
        "            # predict_draw_numbers = [int(input(\"予測したい開催回を入力してください: \"))] # インタラクティブな場合\n",
        "        elif mode == 'train':\n",
        "             predict_draw_numbers = [620,621,622,623,624,625,626,627,628,629,630] # トレーニング中に予測する開催回\n",
        "\n",
        "    # Load minimal data to get last draw number\n",
        "    last_actual_draw = 0\n",
        "    try:\n",
        "        response = requests.get(\"https://loto7.thekyo.jp/data/loto7.csv\")\n",
        "        response.encoding = 'shift_jis'\n",
        "        df_temp = pd.read_csv(io.StringIO(response.text))\n",
        "        last_actual_draw = df_temp['開催回'].values[-1]\n",
        "        del df_temp # Free up memory\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load initial data to check last draw number: {e}\")\n",
        "\n",
        "    # Determine predict_future based on whether any requested draw number is beyond the last actual draw\n",
        "    should_predict_future = predict_draw_numbers and any(num > last_actual_draw for num in predict_draw_numbers)\n",
        "\n",
        "    # データセット初期化（未来予測モードで初期化）\n",
        "    dataset = EnhancedLoto7Dataset(\n",
        "        \"https://loto7.thekyo.jp/data/loto7.csv\",\n",
        "        window_size=10,\n",
        "        predict_future=should_predict_future\n",
        "    )\n",
        "\n",
        "    if predict_only:\n",
        "        # 予測のみモード\n",
        "        models = []\n",
        "        for i in range(3): # 3モデルをロードしようとする\n",
        "            model_path = f\"loto7_enhanced_epoch1000_model{i}.pth\"\n",
        "            if os.path.exists(model_path):\n",
        "                model = EnhancedLoto7Transformer(window_size=10)\n",
        "                model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
        "                model.eval()\n",
        "                models.append(model)\n",
        "            else:\n",
        "                logger.warning(f\"Model file not found: {model_path}. Skipping model {i}.\")\n",
        "\n",
        "        if not models:\n",
        "             logger.error(\"予測に使えるモデルが見つかりませんでした。\")\n",
        "             sys.exit(1)\n",
        "\n",
        "        # 各開催回に対して予測\n",
        "        for draw_num in predict_draw_numbers:\n",
        "            try:\n",
        "                # 未来の開催回の場合は予測結果を使用\n",
        "                use_predicted = draw_num > dataset.draw_numbers[-1]\n",
        "                predictions = generate_ensemble_predictions(\n",
        "                    models, dataset, draw_num,\n",
        "                    num_preds=5,\n",
        "                    visualize=True,\n",
        "                    use_predicted=use_predicted\n",
        "                )\n",
        "\n",
        "                # 結果を保存\n",
        "                if predictions: # Only save if predictions were generated (e.g., not empty list from error)\n",
        "                    # アンサンブル予測結果をCSVとして保存\n",
        "                    pd.DataFrame(predictions, columns=[f'Num{j+1}' for j in range(7)]).to_csv(f\"predictions_{draw_num}.csv\", index=False)\n",
        "                    logger.info(f\"Ensemble prediction results for draw {draw_num} saved\")\n",
        "\n",
        "                    # 未来の開催回の場合は予測結果をデータセットに追加\n",
        "                    # generate_ensemble_predictionsは[result]を返すため、predictions[0]を使用\n",
        "                    if use_predicted and predictions[0]:\n",
        "                         dataset.add_prediction(draw_num, predictions[0])\n",
        "                else:\n",
        "                    logger.warning(f\"No predictions generated for draw {draw_num}, skipping save and history add.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Prediction failed for draw {draw_num}: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # トレーニングモード\n",
        "    # ハイパフォーマンスデータローダー\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=512,\n",
        "        shuffle=True,\n",
        "        num_workers=os.cpu_count(),\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    # モデルとトレーナーの作成\n",
        "    models = [EnhancedLoto7Transformer(window_size=10) for _ in range(3)]\n",
        "    # トレーナーにモデルのインデックスを渡す\n",
        "    trainers = [AdvancedTrainer(model, predict_draw_numbers=predict_draw_numbers, model_idx=i) for i, model in enumerate(models)]\n",
        "\n",
        "    # トレーニング実行\n",
        "    num_epochs = 100001\n",
        "    save_interval = 1000\n",
        "\n",
        "    for epoch in range(1, num_epochs):\n",
        "        for trainer in trainers:\n",
        "            # Pass the dataset to train_epoch for prediction feature\n",
        "            trainer.train_epoch(epoch, loader, dataset)\n",
        "\n",
        "        # モデル保存 (既存のロジック、epoch % save_interval == 0 で保存)\n",
        "        if epoch % save_interval == 0:\n",
        "            for i, model in enumerate(models):\n",
        "                try:\n",
        "                    torch.save(model.state_dict(), f\"loto7_epoch{epoch}_model{i}.pth\")\n",
        "                    logger.info(f\"Model loto7_enhanced_epoch{epoch}_model{i}.pth saved.\")\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Failed to save model epoch {epoch} model {i}: {e}\")\n",
        "\n",
        "        for i, model in enumerate(models):\n",
        "           torch.save(model.state_dict(), f\"loto7_model{i}.pth\")\n",
        "\n",
        "# Placeholder classes (Retained for completeness, replace with your actual implementations)\n",
        "class EnhancedRotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim, base=10000):\n",
        "        super().__init__()\n",
        "        inv_freq = 1. / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.shape[1]\n",
        "        t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)\n",
        "        freqs = torch.einsum('i,j->ij', t, self.inv_freq)\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        return emb\n",
        "\n",
        "def apply_rotary_pos_emb(pos, qk):\n",
        "    if qk.ndim == 4: # For QK (batch, heads, seq_len, head_dim)\n",
        "        seq_len = qk.shape[2]\n",
        "        # Placeholder rotation - replace with actual RoPE rotation\n",
        "        pos_expanded = pos.unsqueeze(1).unsqueeze(1).expand_as(qk)\n",
        "        return qk + pos_expanded # Simplified addition, not real RoPE rotation\n",
        "    elif qk.ndim == 3: # For combined input (batch, seq_len, dim)\n",
        "         seq_len = qk.shape[1]\n",
        "         # Placeholder rotation - replace with actual RoPE rotation\n",
        "         pos_expanded = pos.unsqueeze(0).expand_as(qk)\n",
        "         return qk + pos_expanded # Simplified addition, not real RoPE rotation\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported input dimensions for apply_rotary_pos_emb\")\n",
        "\n",
        "\n",
        "class EnhancedTransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, nhead):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_model * 4, d_model)\n",
        "        )\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, src):\n",
        "        x = self.norm1(src)\n",
        "        attn_output, _ = self.attn(x, x, x)\n",
        "        x = src + self.dropout1(attn_output)\n",
        "        x = x + self.dropout2(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class EnhancedRotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim, base=10000):\n",
        "        super().__init__()\n",
        "        # Placeholder: Your actual Rotary Embedding implementation\n",
        "        # Example:\n",
        "        inv_freq = 1. / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Placeholder: Apply RoPE\n",
        "        # x shape: (batch, seq_len, dim)\n",
        "        seq_len = x.shape[1]\n",
        "        t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)\n",
        "        freqs = torch.einsum('i,j->ij', t, self.inv_freq)\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        return emb # Returning embedding to be used by apply_rotary_pos_emb\n",
        "\n",
        "def apply_rotary_pos_emb(pos, qk):\n",
        "    # Placeholder: Apply Rotary Position Embedding\n",
        "    # pos shape: (seq_len, dim)\n",
        "    # qk shape: (batch, num_heads, seq_len, head_dim) or (batch, seq_len, dim)\n",
        "    # Your actual implementation of applying RoPE rotation\n",
        "    # Example (simplified):\n",
        "    if qk.ndim == 4: # For QK (batch, heads, seq_len, head_dim)\n",
        "        seq_len = qk.shape[2]\n",
        "        pos = pos.unsqueeze(1).unsqueeze(1) # (seq_len, 1, 1, dim)\n",
        "        return qk + pos # This is NOT how RoPE works, replace with actual rotation logic\n",
        "    elif qk.ndim == 3: # For combined input (batch, seq_len, dim)\n",
        "         seq_len = qk.shape[1]\n",
        "         pos = pos.unsqueeze(0) # (1, seq_len, dim)\n",
        "         return qk + pos # This is NOT how RoPE works, replace with actual rotation logic\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported input dimensions for apply_rotary_pos_emb\")\n",
        "\n",
        "\n",
        "class EnhancedTransformerEncoder(nn.Module):\n",
        "    def __init__(self, d_model, nhead):\n",
        "        super().__init__()\n",
        "        # Placeholder: Your actual Transformer Encoder layer\n",
        "        # Example using standard PyTorch TransformerEncoderLayer:\n",
        "        # from torch.nn import TransformerEncoderLayer\n",
        "        # self.layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward=d_model*4, dropout=0.1, batch_first=True)\n",
        "        # Replace with your custom implementation if needed\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_model * 4, d_model)\n",
        "        )\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # Placeholder: Transformer Encoder forward pass\n",
        "        # x = self.layer(src) # Using standard layer\n",
        "        # Custom layer forward:\n",
        "        x = self.norm1(src)\n",
        "        # MultiheadAttention expects query, key, value. For self-attention, they are the same.\n",
        "        # It also needs a mask if sequence length varies, but here it's fixed window_size.\n",
        "        # Check return format: (output, attn_output_weights)\n",
        "        attn_output, _ = self.attn(x, x, x)\n",
        "        x = src + self.dropout1(attn_output)\n",
        "        x = x + self.dropout2(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5i8roLJo5LW"
      },
      "outputs": [],
      "source": [
        "!pip install apex transformers datasets tokenizers\n",
        "!pip install pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1, 6, 13, 19, 25, 21, 37] _\n",
        "[2, 4, 8, 16, 19, 36, 32] _\n",
        "[1, 6, 11, 16, 25, 26, 35] _\n",
        "[1, 10, 8, 16, 27, 24, 35] _\n",
        "[1, 7, 15, 16, 27, 31, 35]"
      ],
      "metadata": {
        "id": "aFbVHKs-gI_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLxBsTlADYyh"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y libstdc++6\n",
        "!sudo apt-get install -y gcc-12 g++-12\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 100\n",
        "!sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-12 100\n",
        "!pip uninstall bitsandbytes\n",
        "!pip install bitsandbytes\n",
        "!pip uninstall deepspeed\n",
        "!pip install deepspeed"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vMI64olPpTZ7iGX1DfX3UtjuR-RAIo6L",
      "authorship_tag": "ABX9TyOA2DiSywFweTCoxzY+JJUz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}